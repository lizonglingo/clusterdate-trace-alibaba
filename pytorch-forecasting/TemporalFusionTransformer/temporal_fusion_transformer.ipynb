{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = pd.read_parquet(\"./data/stallion.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>labor_day</th>\n",
       "      <th>independence_day</th>\n",
       "      <th>revolution_day_memorial</th>\n",
       "      <th>regional_games</th>\n",
       "      <th>fifa_u_17_world_cup</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agency_22</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>52.2720</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1168.903668</td>\n",
       "      <td>1069.166193</td>\n",
       "      <td>99.737475</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.532566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Agency_37</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>26.505000</td>\n",
       "      <td>1852.273642</td>\n",
       "      <td>1611.466298</td>\n",
       "      <td>240.807344</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000635</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Agency_59</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>812.9214</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>22.219737</td>\n",
       "      <td>1270.795012</td>\n",
       "      <td>1197.184260</td>\n",
       "      <td>73.610752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.792496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>316.4400</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.360000</td>\n",
       "      <td>1176.155397</td>\n",
       "      <td>1082.757488</td>\n",
       "      <td>93.397909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.940950</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>420.9093</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>24.079012</td>\n",
       "      <td>1327.003396</td>\n",
       "      <td>1207.822992</td>\n",
       "      <td>119.180404</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.981168</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        agency     sku    volume       date  industry_volume  soda_volume  \\\n",
       "0    Agency_22  SKU_01   52.2720 2013-01-01        492612703    718394219   \n",
       "238  Agency_37  SKU_04    0.0000 2013-01-01        492612703    718394219   \n",
       "237  Agency_59  SKU_03  812.9214 2013-01-01        492612703    718394219   \n",
       "236  Agency_11  SKU_01  316.4400 2013-01-01        492612703    718394219   \n",
       "235  Agency_05  SKU_05  420.9093 2013-01-01        492612703    718394219   \n",
       "\n",
       "     avg_max_temp  price_regular  price_actual    discount  ...  labor_day  \\\n",
       "0       25.845238    1168.903668   1069.166193   99.737475  ...          0   \n",
       "238     26.505000    1852.273642   1611.466298  240.807344  ...          0   \n",
       "237     22.219737    1270.795012   1197.184260   73.610752  ...          0   \n",
       "236     25.360000    1176.155397   1082.757488   93.397909  ...          0   \n",
       "235     24.079012    1327.003396   1207.822992  119.180404  ...          0   \n",
       "\n",
       "     independence_day  revolution_day_memorial  regional_games  \\\n",
       "0                   0                        0               0   \n",
       "238                 0                        0               0   \n",
       "237                 0                        0               0   \n",
       "236                 0                        0               0   \n",
       "235                 0                        0               0   \n",
       "\n",
       "     fifa_u_17_world_cup  football_gold_cup  beer_capital  music_fest  \\\n",
       "0                      0                  0             0           0   \n",
       "238                    0                  0             0           0   \n",
       "237                    0                  0             0           0   \n",
       "236                    0                  0             0           0   \n",
       "235                    0                  0             0           0   \n",
       "\n",
       "     discount_in_percent  timeseries  \n",
       "0               8.532566           0  \n",
       "238            13.000635           5  \n",
       "237             5.792496           9  \n",
       "236             7.940950          14  \n",
       "235             8.981168          22  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21000 entries, 0 to 6650\n",
      "Data columns (total 26 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   agency                            21000 non-null  category      \n",
      " 1   sku                               21000 non-null  category      \n",
      " 2   volume                            21000 non-null  float64       \n",
      " 3   date                              21000 non-null  datetime64[ns]\n",
      " 4   industry_volume                   21000 non-null  int64         \n",
      " 5   soda_volume                       21000 non-null  int64         \n",
      " 6   avg_max_temp                      21000 non-null  float64       \n",
      " 7   price_regular                     21000 non-null  float64       \n",
      " 8   price_actual                      21000 non-null  float64       \n",
      " 9   discount                          21000 non-null  float64       \n",
      " 10  avg_population_2017               21000 non-null  int64         \n",
      " 11  avg_yearly_household_income_2017  21000 non-null  int64         \n",
      " 12  easter_day                        21000 non-null  int64         \n",
      " 13  good_friday                       21000 non-null  int64         \n",
      " 14  new_year                          21000 non-null  int64         \n",
      " 15  christmas                         21000 non-null  int64         \n",
      " 16  labor_day                         21000 non-null  int64         \n",
      " 17  independence_day                  21000 non-null  int64         \n",
      " 18  revolution_day_memorial           21000 non-null  int64         \n",
      " 19  regional_games                    21000 non-null  int64         \n",
      " 20  fifa_u_17_world_cup               21000 non-null  int64         \n",
      " 21  football_gold_cup                 21000 non-null  int64         \n",
      " 22  beer_capital                      21000 non-null  int64         \n",
      " 23  music_fest                        21000 non-null  int64         \n",
      " 24  discount_in_percent               21000 non-null  float64       \n",
      " 25  timeseries                        21000 non-null  int64         \n",
      "dtypes: category(2), datetime64[ns](1), float64(6), int64(17)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Agency_25</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1264.162234</td>\n",
       "      <td>1152.473405</td>\n",
       "      <td>111.688829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.835008</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>99.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Agency_29</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>8.7480</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>498567142</td>\n",
       "      <td>762225057</td>\n",
       "      <td>27.584615</td>\n",
       "      <td>1316.098485</td>\n",
       "      <td>1296.804924</td>\n",
       "      <td>19.293561</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>177</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168825</td>\n",
       "      <td>1634.434615</td>\n",
       "      <td>11.397086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>Agency_47</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>4.9680</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>454252482</td>\n",
       "      <td>789624076</td>\n",
       "      <td>30.665957</td>\n",
       "      <td>1269.250000</td>\n",
       "      <td>1266.490490</td>\n",
       "      <td>2.759510</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.217413</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.603017</td>\n",
       "      <td>2625.472644</td>\n",
       "      <td>48.295650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Agency_53</td>\n",
       "      <td>SKU_07</td>\n",
       "      <td>21.6825</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>480693900</td>\n",
       "      <td>791658684</td>\n",
       "      <td>29.197727</td>\n",
       "      <td>1193.842373</td>\n",
       "      <td>1128.124395</td>\n",
       "      <td>65.717978</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>beer_capital</td>\n",
       "      <td>-</td>\n",
       "      <td>5.504745</td>\n",
       "      <td>240</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3.076505</td>\n",
       "      <td>38.529107</td>\n",
       "      <td>2511.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>Agency_17</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>960.5520</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>515468092</td>\n",
       "      <td>871204688</td>\n",
       "      <td>23.608120</td>\n",
       "      <td>1338.334248</td>\n",
       "      <td>1232.128069</td>\n",
       "      <td>106.206179</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>7.935699</td>\n",
       "      <td>259</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6.867508</td>\n",
       "      <td>2143.677462</td>\n",
       "      <td>396.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>1184.6535</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>425528909</td>\n",
       "      <td>734443953</td>\n",
       "      <td>28.668254</td>\n",
       "      <td>1369.556376</td>\n",
       "      <td>1161.135214</td>\n",
       "      <td>208.421162</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.218151</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7.077206</td>\n",
       "      <td>1566.643589</td>\n",
       "      <td>1881.866367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>5.5593</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>623319783</td>\n",
       "      <td>1049868815</td>\n",
       "      <td>31.915385</td>\n",
       "      <td>1922.486644</td>\n",
       "      <td>1651.307674</td>\n",
       "      <td>271.178970</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>14.105636</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1.715472</td>\n",
       "      <td>1385.225478</td>\n",
       "      <td>109.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>Agency_48</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>4275.1605</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>509281531</td>\n",
       "      <td>892192092</td>\n",
       "      <td>26.767857</td>\n",
       "      <td>1761.258209</td>\n",
       "      <td>1546.059670</td>\n",
       "      <td>215.198539</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>12.218455</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.360577</td>\n",
       "      <td>1757.950603</td>\n",
       "      <td>1925.272108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>Agency_07</td>\n",
       "      <td>SKU_21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>544203593</td>\n",
       "      <td>761469815</td>\n",
       "      <td>28.987755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2418.719550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12084</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>46.3608</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>589969396</td>\n",
       "      <td>940912941</td>\n",
       "      <td>32.478910</td>\n",
       "      <td>1675.922116</td>\n",
       "      <td>1413.571789</td>\n",
       "      <td>262.350327</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.654088</td>\n",
       "      <td>181</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3.836454</td>\n",
       "      <td>2034.293024</td>\n",
       "      <td>109.381800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          agency     sku     volume       date  industry_volume  soda_volume  \\\n",
       "291    Agency_25  SKU_03     0.5076 2013-01-01        492612703    718394219   \n",
       "871    Agency_29  SKU_02     8.7480 2015-01-01        498567142    762225057   \n",
       "19532  Agency_47  SKU_01     4.9680 2013-09-01        454252482    789624076   \n",
       "2089   Agency_53  SKU_07    21.6825 2013-10-01        480693900    791658684   \n",
       "9755   Agency_17  SKU_02   960.5520 2015-03-01        515468092    871204688   \n",
       "7561   Agency_05  SKU_03  1184.6535 2014-02-01        425528909    734443953   \n",
       "19204  Agency_11  SKU_05     5.5593 2017-08-01        623319783   1049868815   \n",
       "8781   Agency_48  SKU_04  4275.1605 2013-03-01        509281531    892192092   \n",
       "2540   Agency_07  SKU_21     0.0000 2015-10-01        544203593    761469815   \n",
       "12084  Agency_21  SKU_03    46.3608 2017-04-01        589969396    940912941   \n",
       "\n",
       "       avg_max_temp  price_regular  price_actual    discount  ...  \\\n",
       "291       25.845238    1264.162234   1152.473405  111.688829  ...   \n",
       "871       27.584615    1316.098485   1296.804924   19.293561  ...   \n",
       "19532     30.665957    1269.250000   1266.490490    2.759510  ...   \n",
       "2089      29.197727    1193.842373   1128.124395   65.717978  ...   \n",
       "9755      23.608120    1338.334248   1232.128069  106.206179  ...   \n",
       "7561      28.668254    1369.556376   1161.135214  208.421162  ...   \n",
       "19204     31.915385    1922.486644   1651.307674  271.178970  ...   \n",
       "8781      26.767857    1761.258209   1546.059670  215.198539  ...   \n",
       "2540      28.987755       0.000000      0.000000    0.000000  ...   \n",
       "12084     32.478910    1675.922116   1413.571789  262.350327  ...   \n",
       "\n",
       "       football_gold_cup  beer_capital  music_fest discount_in_percent  \\\n",
       "291                    -             -           -            8.835008   \n",
       "871                    -             -           -            1.465966   \n",
       "19532                  -             -           -            0.217413   \n",
       "2089                   -  beer_capital           -            5.504745   \n",
       "9755                   -             -  music_fest            7.935699   \n",
       "7561                   -             -           -           15.218151   \n",
       "19204                  -             -           -           14.105636   \n",
       "8781                   -             -  music_fest           12.218455   \n",
       "2540                   -             -           -            0.000000   \n",
       "12084                  -             -           -           15.654088   \n",
       "\n",
       "      timeseries time_idx month log_volume avg_volume_by_sku  \\\n",
       "291          228        0     1  -0.678062       1225.306376   \n",
       "871          177       24     1   2.168825       1634.434615   \n",
       "19532        322        8     9   1.603017       2625.472644   \n",
       "2089         240        9    10   3.076505         38.529107   \n",
       "9755         259       26     3   6.867508       2143.677462   \n",
       "7561          21       13     2   7.077206       1566.643589   \n",
       "19204         17       55     8   1.715472       1385.225478   \n",
       "8781         151        2     3   8.360577       1757.950603   \n",
       "2540         300       33    10 -18.420681          0.000000   \n",
       "12084        181       51     4   3.836454       2034.293024   \n",
       "\n",
       "      avg_volume_by_agency  \n",
       "291              99.650400  \n",
       "871              11.397086  \n",
       "19532            48.295650  \n",
       "2089           2511.035175  \n",
       "9755            396.022140  \n",
       "7561           1881.866367  \n",
       "19204           109.699200  \n",
       "8781           1925.272108  \n",
       "2540           2418.719550  \n",
       "12084           109.381800  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "\n",
    "# add additional features\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"agency\"], observed=True).volume.transform(\"mean\")\n",
    "\n",
    "# we want to encode special days as one variable and thus need to first reverse one-hot encoding\n",
    "special_days = [\n",
    "    \"easter_day\",\n",
    "    \"good_friday\",\n",
    "    \"new_year\",\n",
    "    \"christmas\",\n",
    "    \"labor_day\",\n",
    "    \"independence_day\",\n",
    "    \"revolution_day_memorial\",\n",
    "    \"regional_games\",\n",
    "    \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\",\n",
    "    \"beer_capital\",\n",
    "    \"music_fest\",\n",
    "]\n",
    "data[special_days] = data[special_days].apply(lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")\n",
    "data.sample(10, random_state=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    "    static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293.0088195800781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d8cfa51b8d4b0dbbec5c012f4b649b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at d:\\Coding\\WorkPlace\\clusterdate-trace-alibaba\\pytorch-forecasting\\TemporalFusionTransformer\\.lr_find_4c58248e-2b12-441a-ad06-a4f0ec1388ab.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.01862087136662867\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lightning_logs\\lightning_logs\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \n",
      "3  | prescalers                         | ModuleDict                      | 256   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "29.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.7 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0613d22ae34d493c9d1fe306077d4b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c061786f57ef43ab8bd0df4b99f685e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd88e1fc0aa44882bb8f83a03bb1ba33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1bc696956e428a866fc3a5ed886072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f337726e06648ed8c2541dde955b01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032671e0a977481a88695c98ae6f0abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19955c0c09e46a4854274ba7052d98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f2bbfdd7da446fbb96dd70cfbf4954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400eff35088646d4aed7567683960034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52686a6496b84a18bb95bdca8bc61334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d29ee337c104b82be0a59fa5a9be86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7574d089b14f44b4d22b36c0a9d1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7ed80237a44645b7ff8752c1469feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973722ab975345d48b3aed629c7b8f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325725bfc7554af0968d6f67de800e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b9ff4570da4973998692953ee38a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50b894b99e448c1a5a8ae8d90bcf591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b2309c53f64304893ee8d9fbe248ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423aff53c1e545b29ee9969532a34146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234e231745fa42529d99e1d3f20dea74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3724c8a8be41cb86c239ed78facc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440e61b25ecf469a8a805f685a1d5c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597230536cbf4bbc9f87bab06e130a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afef235140bd4150aecaa94f81bf0ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885a7c1ac04b424d86c20a9240c2fa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-12 13:31:23,056]\u001b[0m A new study created in memory with name: no-name-dab3aca4-8b45-4d10-8c04-3bd29bdbdf7e\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 13:49:02,685]\u001b[0m Trial 0 finished with value: 152.63226318359375 and parameters: {'gradient_clip_val': 0.5726776874810338, 'hidden_size': 37, 'dropout': 0.11593768689786606, 'hidden_continuous_size': 11, 'attention_head_size': 1, 'learning_rate': 0.0028088633500398643}. Best is trial 0 with value: 152.63226318359375.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:06:12,942]\u001b[0m Trial 1 finished with value: 184.49168395996094 and parameters: {'gradient_clip_val': 0.010998153479847379, 'hidden_size': 28, 'dropout': 0.20094179684751087, 'hidden_continuous_size': 9, 'attention_head_size': 3, 'learning_rate': 0.07516066326188632}. Best is trial 0 with value: 152.63226318359375.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:06:46,333]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:08:56,594]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:15:47,215]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:16:25,940]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:17:07,193]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:17:57,037]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:18:49,851]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:24:23,793]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:25:00,067]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:25:46,410]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:27:05,344]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:27:42,266]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:28:27,495]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:29:06,000]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:29:50,037]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:30:26,954]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:31:09,732]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:34:15,773]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:35:02,743]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:35:42,794]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:36:21,835]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 14:54:07,729]\u001b[0m Trial 23 finished with value: 165.11289978027344 and parameters: {'gradient_clip_val': 0.12692254538335512, 'hidden_size': 30, 'dropout': 0.12626995682771242, 'hidden_continuous_size': 20, 'attention_head_size': 3, 'learning_rate': 0.07120357446328612}. Best is trial 0 with value: 152.63226318359375.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:00:04,003]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:05:52,748]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:06:41,182]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:07:19,305]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:08:02,620]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:08:36,451]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:09:12,402]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:10:58,609]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:11:39,856]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:14:23,287]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:16:13,945]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:17:02,505]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:17:44,619]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:18:23,134]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:19:01,423]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:20:49,960]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:21:28,992]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:23:07,581]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:23:46,344]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:24:31,409]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:25:14,481]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:25:52,331]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:26:42,813]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:27:27,592]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:28:14,717]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:28:56,475]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:29:33,878]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:30:14,278]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:32:03,071]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:32:43,512]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:33:28,497]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:34:08,076]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:34:52,720]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:35:32,463]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:37:17,430]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:38:54,477]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:39:38,190]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:40:43,926]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:42:53,834]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:43:41,439]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:45:37,239]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:46:29,560]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:47:10,964]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:47:48,022]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:48:30,818]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:49:19,971]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:50:05,091]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:55:58,535]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:56:42,544]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:57:22,788]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:58:00,947]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 15:58:41,109]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:00:29,505]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:06:34,855]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:07:20,035]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:08:02,291]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:09:49,749]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:16:19,596]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:22:39,418]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:23:25,169]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:25:21,853]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:26:07,102]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:27:52,469]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:28:39,065]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:46:55,053]\u001b[0m Trial 88 finished with value: 158.04249572753906 and parameters: {'gradient_clip_val': 0.08702901543570525, 'hidden_size': 38, 'dropout': 0.14449651343661696, 'hidden_continuous_size': 24, 'attention_head_size': 3, 'learning_rate': 0.05105915859238627}. Best is trial 0 with value: 152.63226318359375.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:47:40,504]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:48:26,002]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:50:15,946]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:51:03,450]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:51:46,958]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:52:32,449]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 16:59:07,765]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:01:06,204]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:01:50,695]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:02:31,402]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:03:17,890]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:04:02,600]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:06:06,955]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:06:51,563]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:07:36,507]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:08:23,721]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:09:16,535]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:10:03,333]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:10:52,246]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:11:31,800]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:12:16,886]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:12:59,271]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:13:43,095]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:14:28,042]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:19:59,029]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:20:43,723]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:21:24,057]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:22:07,215]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:22:54,997]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:23:39,607]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m[I 2022-06-12 17:25:28,681]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcf34018491d9bd3ef31166662b4dd1e52e7c1b62f1d6d6644835049dcdb0d97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
